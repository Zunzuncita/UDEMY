{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de8527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.kernel_approximation import RBFSampler, Nystroem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment description\n",
    "rewards={(0,3):1,(1,3):-1}\n",
    "\n",
    "actions={\n",
    "    (2,0):['U','R'],\n",
    "    (1,0):['U','D'],\n",
    "    (0,0):['R','D'],\n",
    "    (2,1):['R','L'],\n",
    "    (0,1):['R','L'],\n",
    "    (2,2):['U','R','L'],\n",
    "    (1,2):['U','D','R'],\n",
    "    (0,2):['R','L','D'],\n",
    "    (2,3):['L'],\n",
    "}\n",
    "\n",
    "probs = {\n",
    "    ((2, 0), 'U'): {(1, 0): 1.0},\n",
    "    ((2, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'R'): {(2, 1): 1.0},\n",
    "    ((1, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((1, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((1, 0), 'L'): {(1, 0): 1.0},\n",
    "    ((1, 0), 'R'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'D'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'R'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'U'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'D'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 1), 'R'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'U'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'D'): {(1, 2): 1.0},\n",
    "    ((0, 2), 'L'): {(0, 1): 1.0},\n",
    "    ((0, 2), 'R'): {(0, 3): 1.0},\n",
    "    ((2, 1), 'U'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'D'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 1), 'R'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'U'): {(1, 2): 1.0},\n",
    "    ((2, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'L'): {(2, 1): 1.0},\n",
    "    ((2, 2), 'R'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'U'): {(1, 3): 1.0},\n",
    "    ((2, 3), 'D'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'L'): {(2, 2): 1.0},\n",
    "    ((2, 3), 'R'): {(2, 3): 1.0},\n",
    "    ((1, 2), 'U'): {(0, 2): 0.5, (1, 3): 0.5},\n",
    "    ((1, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((1, 2), 'L'): {(1, 2): 1.0},\n",
    "    ((1, 2), 'R'): {(1, 3): 1.0},\n",
    "  }\n",
    "\n",
    "policy = {\n",
    "    (2, 0): 'U',\n",
    "    (1, 0): 'U',\n",
    "    (0, 0): 'R',\n",
    "    (0, 1): 'R',\n",
    "    (0, 2): 'R',\n",
    "    (1, 2): 'R',\n",
    "    (2, 1): 'R',\n",
    "    (2, 2): 'R',\n",
    "    (2, 3): 'U'\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47134f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class WindyGridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions, probs):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.probs = probs\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        #print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "    \n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        cur_state = (self.i, self.j)\n",
    "        a = action\n",
    "        next_action_prob = self.probs[(cur_state,a)]\n",
    "        next_actions = list(next_action_prob.keys())\n",
    "        next_probs = list(next_action_prob.values())\n",
    "        next_state_idx = np.random.choice(len(next_actions), p=next_probs)\n",
    "        self.i = next_actions[next_state_idx][0]\n",
    "        self.j = next_actions[next_state_idx][1]\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d089207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class GridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "\n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def get_next_state(self, s, a):\n",
    "        i, j = s[0], s[1]\n",
    "        #print(f\"s : ({i},{j})\")\n",
    "        #print(a)\n",
    "        #print(self.actions[(i,j)])\n",
    "        if a in self.actions[(i,j)]:\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            elif a == 'R':\n",
    "                j += 1\n",
    "            elif a == 'L':\n",
    "                j -= 1\n",
    "            else:\n",
    "                i += 1\n",
    "        #print(f\"s2 : ({i},{j})\")\n",
    "        return i,j\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i -= 1\n",
    "            elif action == 'R':\n",
    "                self.j += 1\n",
    "            elif action == 'L':\n",
    "                self.j -= 1\n",
    "            else:\n",
    "                self.i += 1\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f02f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values(V,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            v = V.get((i,j),0)\n",
    "            if v >= 0:\n",
    "                print(\" %.2f|\" % v, end=\"\")\n",
    "            else:\n",
    "                print(\"%.2f|\" % v, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "def print_policy(P,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            a = P.get((i,j),' ')\n",
    "            print(\" %s |\" % a, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "ACTION_SPACE = ('U', 'D', 'L', 'R')\n",
    "ACTION2INT = {a: i for i, a in enumerate(ACTION_SPACE)}\n",
    "INT2ONEHOT = np.eye(len(ACTION_SPACE))\n",
    "\n",
    "def init_windy_grid_world_penalized(step_cost, start):\n",
    "    grid = WindyGridWorld(3,4,start)\n",
    "    rewards = {\n",
    "        (2,0):step_cost,\n",
    "        (1,0):step_cost,\n",
    "        (0,0):step_cost,\n",
    "        (2,1):step_cost,\n",
    "        (0,1):step_cost,\n",
    "        (2,2):step_cost,\n",
    "        (1,2):step_cost,\n",
    "        (0,2):step_cost,\n",
    "        (2,3):step_cost,\n",
    "        (0,3):1,\n",
    "        (1,3):-1\n",
    "    }\n",
    "    grid.set_rewards_actions(rewards, actions, probs)\n",
    "    return grid\n",
    "\n",
    "def max_dict(d):\n",
    "    '''\n",
    "    return the argmax and max value from a dictionnary\n",
    "    '''\n",
    "    max_val = max(d.values())\n",
    "    max_keys = [key for key, val in d.items() if val == max_val]\n",
    "    return np.random.choice(max_keys), max_val\n",
    "\n",
    "def epsilon_greedy(model, state, eps=0.1):\n",
    "    '''\n",
    "    return an actions based on the epsilon greedy concept : exploration vs exploitation\n",
    "    random action if < epx else best action\n",
    "    '''\n",
    "    p = np.random.random()\n",
    "    if p < eps:\n",
    "        a = np.random.choice(ACTION_SPACE)\n",
    "    else:\n",
    "        values = model.predict_all_actions(state)\n",
    "        a = ACTION_SPACE[np.argmax(values)]\n",
    "    return a\n",
    "\n",
    "def one_hot(k):\n",
    "    return INT2ONEHOT[k]\n",
    "\n",
    "def merge_state_action(s,a):\n",
    "    ai = one_hot(ACTION2INT[a])\n",
    "    return np.concatenate((s, ai))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6764aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "\n",
    "def gather_samples(grid, n_episodes = 10000):\n",
    "    '''\n",
    "    return a dataset to feed a model with X_train dataset \n",
    "    Not requested for RBF but it's a more generic implementation\n",
    "    '''\n",
    "    samples = []\n",
    "    for _ in range(n_episodes):\n",
    "        s = grid.reset()\n",
    "        \n",
    "        while grid.game_over():\n",
    "            a = np.random.choice(ACTION_SPACE)\n",
    "            sa = merge_state_action(s,a)\n",
    "            samples.append(sa)\n",
    "            \n",
    "            r = grid.move(a)\n",
    "            s = grid.current_state()\n",
    "    return samples\n",
    "\n",
    "class Model:\n",
    "    '''\n",
    "    implement the model of the linear regression with the phi transformation\n",
    "    '''\n",
    "    def __init__(self, grid):\n",
    "        '''\n",
    "        constructor that fit the featurizer phi to data\n",
    "        '''\n",
    "        samples = gather_samples(grid)\n",
    "        self.featurizer = RBFSampler()\n",
    "        self.featurizer.fit(samples)\n",
    "        dims = self.featurizer.random_offset_.shape[0]\n",
    "        \n",
    "        # initialize linear model weights\n",
    "        self.w = np.zeros(dims)\n",
    "\n",
    "    def predict(self, s, a):\n",
    "        sa = merge_state_action(s,a)\n",
    "        x = self.featurizer.transform([sa])[0]\n",
    "        return x @ self.w\n",
    "    \n",
    "    def predict_all_actions(self, s):\n",
    "        return [self.predict(s,a) for a in ACTION_SPACE]\n",
    "    \n",
    "    def grad(self, s, a):\n",
    "        sa = merge_state_action(s,a)\n",
    "        x = self.featurizer.transform([sa])[0]\n",
    "        return x\n",
    "    \n",
    "def main(step_cost, tot_iteration):\n",
    "    \n",
    "    gamma = 0.9    \n",
    "    ALPHA = 0.1\n",
    "\n",
    "        \n",
    "    # initialize G and returns\n",
    "    #g = init_grid_world_penalized(step_cost, (2,0))\n",
    "    g = GridWorld(3,4,(2,0))\n",
    "    g.set_rewards_actions(rewards=rewards, actions=actions)\n",
    "    \n",
    "    print(f\"rewards : \")\n",
    "    print_values(g.rewards,g)\n",
    "    \n",
    "    # use the given policy\n",
    "    \n",
    "    # create the Model\n",
    "    model = Model(g)\n",
    "    reward_per_episode = []\n",
    "    state_visit_count = {}\n",
    "      \n",
    "    #loop on tot_iteration\n",
    "    for t in range(tot_iteration):\n",
    "        if (t+1) % 100 == 0:\n",
    "            print(t+1)\n",
    "           \n",
    "        cur_s = g.reset()\n",
    "        state_visit_count[cur_s] = state_visit_count.get(cur_s, 0) + 1\n",
    "        episode_reward = 0\n",
    "        #compute V based on rewards and next state\n",
    "        while g.game_over():\n",
    "            a = epsilon_greedy(model, cur_s)\n",
    "            \n",
    "            r = g.move(a)\n",
    "            next_s = g.current_state() \n",
    "            state_visit_count[next_s] = state_visit_count.get(next_s, 0) + 1\n",
    "            \n",
    "            # compute the target\n",
    "            if g.is_terminal(next_s):\n",
    "                target = r\n",
    "            else:\n",
    "                values = model.predict_all_actions(next_s)\n",
    "                target = r + gamma * np.max(values)\n",
    "            \n",
    "            # equivalent to calculate the gradient descent - small step on w weight for convergence of the loss function \n",
    "            # with phi = id\n",
    "            cur_g = model.grad(cur_s, a)\n",
    "            err = target - model.predict(cur_s, a)\n",
    "            model.w += ALPHA * err * cur_g\n",
    "            \n",
    "            # accumulate error\n",
    "            episode_reward += r\n",
    "\n",
    "            # update state\n",
    "            cur_s = next_s\n",
    "                        \n",
    "        #update delta\n",
    "        reward_per_episode.append(episode_reward)\n",
    "        \n",
    "    plt.plot(reward_per_episode)\n",
    "    plt.title(\"Reward per episode\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    # find V\n",
    "    V = {}\n",
    "    greedy_policy = {}\n",
    "    states = g.all_states\n",
    "    for s in states:\n",
    "        if s in g.actions:\n",
    "            values = model.predict_all_actions(s)\n",
    "            V[s] = np.max(values)\n",
    "            greedy_policy[s] = ACTION_SPACE[np.argmax(values)]\n",
    "        else:\n",
    "            V[s]=0\n",
    " \n",
    "    print(\"finale policy\")\n",
    "    print_policy(greedy_policy,g)\n",
    "    print(\"final values:\")\n",
    "    print_values(V,g)\n",
    "    \n",
    "    print(\"state_sample_count: \")\n",
    "    state_sample_count_arr = np.zeros((g.rows, g.columns))\n",
    "    for i in range(g.rows):\n",
    "        for j in range(g.columns):\n",
    "            if (i,j) in state_visit_count:\n",
    "                state_sample_count_arr[i,j] = state_visit_count[(i,j)]\n",
    "    df = pd.DataFrame(state_sample_count_arr)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "331bf9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1), (1, 2), (0, 0), (1, 3), (2, 1), (2, 0), (2, 3), (2, 2), (1, 0), (0, 2), (0, 3)}\n",
      "rewards : \n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finale policy\n",
      "---------------------------\n",
      " R | R | R |   |\n",
      "---------------------------\n",
      " U |   | U |   |\n",
      "---------------------------\n",
      " U | U | U | U |\n",
      "final values:\n",
      "---------------------------\n",
      " 0.81| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.88| 0.00|\n",
      "---------------------------\n",
      " 0.66| 0.58| 0.77| 0.32|\n",
      "state_sample_count: \n",
      "         0        1        2        3\n",
      "0  22274.0  22253.0  21594.0  19975.0\n",
      "1  22249.0      0.0    715.0     25.0\n",
      "2  22604.0    823.0    319.0     63.0\n"
     ]
    }
   ],
   "source": [
    "main(-0.05, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514294da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
