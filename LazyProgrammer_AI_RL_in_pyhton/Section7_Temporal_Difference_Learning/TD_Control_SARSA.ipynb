{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de8527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment description\n",
    "rewards={(0,3):1,(1,3):-1}\n",
    "\n",
    "actions={\n",
    "    (2,0):['U','R'],\n",
    "    (1,0):['U','D'],\n",
    "    (0,0):['R','D'],\n",
    "    (2,1):['R','L'],\n",
    "    (0,1):['R','L'],\n",
    "    (2,2):['U','R','L'],\n",
    "    (1,2):['U','D','R'],\n",
    "    (0,2):['R','L','D'],\n",
    "    (2,3):['L'],\n",
    "}\n",
    "\n",
    "probs = {\n",
    "    ((2, 0), 'U'): {(1, 0): 1.0},\n",
    "    ((2, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'R'): {(2, 1): 1.0},\n",
    "    ((1, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((1, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((1, 0), 'L'): {(1, 0): 1.0},\n",
    "    ((1, 0), 'R'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'D'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'R'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'U'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'D'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 1), 'R'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'U'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'D'): {(1, 2): 1.0},\n",
    "    ((0, 2), 'L'): {(0, 1): 1.0},\n",
    "    ((0, 2), 'R'): {(0, 3): 1.0},\n",
    "    ((2, 1), 'U'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'D'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 1), 'R'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'U'): {(1, 2): 1.0},\n",
    "    ((2, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'L'): {(2, 1): 1.0},\n",
    "    ((2, 2), 'R'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'U'): {(1, 3): 1.0},\n",
    "    ((2, 3), 'D'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'L'): {(2, 2): 1.0},\n",
    "    ((2, 3), 'R'): {(2, 3): 1.0},\n",
    "    ((1, 2), 'U'): {(0, 2): 0.5, (1, 3): 0.5},\n",
    "    ((1, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((1, 2), 'L'): {(1, 2): 1.0},\n",
    "    ((1, 2), 'R'): {(1, 3): 1.0},\n",
    "  }\n",
    "\n",
    "policy = {\n",
    "    (2, 0): 'U',\n",
    "    (1, 0): 'U',\n",
    "    (0, 0): 'R',\n",
    "    (0, 1): 'R',\n",
    "    (0, 2): 'R',\n",
    "    (1, 2): 'R',\n",
    "    (2, 1): 'R',\n",
    "    (2, 2): 'R',\n",
    "    (2, 3): 'U'\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47134f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class WindyGridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions, probs):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.probs = probs\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        #print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "    \n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        cur_state = (self.i, self.j)\n",
    "        a = action\n",
    "        next_action_prob = self.probs[(cur_state,a)]\n",
    "        next_actions = list(next_action_prob.keys())\n",
    "        next_probs = list(next_action_prob.values())\n",
    "        next_state_idx = np.random.choice(len(next_actions), p=next_probs)\n",
    "        self.i = next_actions[next_state_idx][0]\n",
    "        self.j = next_actions[next_state_idx][1]\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d089207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class GridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "\n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def get_next_state(self, s, a):\n",
    "        i, j = s[0], s[1]\n",
    "        #print(f\"s : ({i},{j})\")\n",
    "        #print(a)\n",
    "        #print(self.actions[(i,j)])\n",
    "        if a in self.actions[(i,j)]:\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            elif a == 'R':\n",
    "                j += 1\n",
    "            elif a == 'L':\n",
    "                j -= 1\n",
    "            else:\n",
    "                i += 1\n",
    "        #print(f\"s2 : ({i},{j})\")\n",
    "        return i,j\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i -= 1\n",
    "            elif action == 'R':\n",
    "                self.j += 1\n",
    "            elif action == 'L':\n",
    "                self.j -= 1\n",
    "            else:\n",
    "                self.i += 1\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f02f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values(V,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            v = V.get((i,j),0)\n",
    "            if v >= 0:\n",
    "                print(\" %.2f|\" % v, end=\"\")\n",
    "            else:\n",
    "                print(\"%.2f|\" % v, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "def print_policy(P,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            a = P.get((i,j),' ')\n",
    "            print(\" %s |\" % a, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "ACTION_SPACE = ('U', 'D', 'L', 'R')\n",
    "\n",
    "def init_windy_grid_world_penalized(step_cost, start):\n",
    "    grid = WindyGridWorld(3,4,start)\n",
    "    rewards = {\n",
    "        (2,0):step_cost,\n",
    "        (1,0):step_cost,\n",
    "        (0,0):step_cost,\n",
    "        (2,1):step_cost,\n",
    "        (0,1):step_cost,\n",
    "        (2,2):step_cost,\n",
    "        (1,2):step_cost,\n",
    "        (0,2):step_cost,\n",
    "        (2,3):step_cost,\n",
    "        (0,3):1,\n",
    "        (1,3):-1\n",
    "    }\n",
    "    grid.set_rewards_actions(rewards, actions, probs)\n",
    "    return grid\n",
    "\n",
    "def max_dict(d):\n",
    "    '''\n",
    "    return the argmax and max value from a dictionnary\n",
    "    '''\n",
    "    max_val = max(d.values())\n",
    "    max_keys = [key for key, val in d.items() if val == max_val]\n",
    "    return np.random.choice(max_keys), max_val\n",
    "\n",
    "def epsilon_greedy(Q, state, eps=0.1):\n",
    "    '''\n",
    "    return an actions based on the epsilon greedy concept : exploration vs exploitation\n",
    "    random action if < epx else best action\n",
    "    '''\n",
    "    p = np.random.random()\n",
    "    if p < eps:\n",
    "        a = np.random.choice(ACTION_SPACE)\n",
    "    else:\n",
    "        a = max_dict(Q[state])[0]\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6764aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-3\n",
    "\n",
    "def main(step_cost, tot_iteration):\n",
    "    \n",
    "    gamma = 0.9    \n",
    "    ALPHA = 0.1\n",
    "        \n",
    "    # initialize G and returns\n",
    "    #g = init_grid_world_penalized(step_cost, (2,0))\n",
    "    g = GridWorld(3,4,(2,0))\n",
    "    g.set_rewards_actions(rewards=rewards, actions=actions)\n",
    "    \n",
    "    print(f\"rewards : \")\n",
    "    print_values(g.rewards,g)\n",
    "    \n",
    "   \n",
    "    # initialize Q(s,a) and returns\n",
    "    Q = {}\n",
    "    state_sample_count = {}\n",
    "    states = g.all_states\n",
    "    for s in states:\n",
    "        Q[s]={}\n",
    "        for a in ACTION_SPACE:\n",
    "            Q[s][a]=0\n",
    "        state_sample_count[s]=0 \n",
    "      \n",
    "    # repeat until convergence\n",
    "    deltas = []\n",
    "    #loop on tot_iteration\n",
    "    for t in range(tot_iteration):\n",
    "        if t % 1000 == 0:\n",
    "            print(t)\n",
    "      \n",
    "        # play one game based on a random policy\n",
    "        biggest_change = 0\n",
    "        #print_policy(policy,g)\n",
    "        \n",
    "        cur_s = g.reset()\n",
    "        cur_a = epsilon_greedy(Q, cur_s)\n",
    "        \n",
    "        #compute Q based on rewards and next state/action\n",
    "        while g.game_over():\n",
    "            state_sample_count[cur_s] += 1 \n",
    "                       \n",
    "            r = g.move(cur_a)\n",
    "            next_s = g.current_state()  \n",
    "            next_a = epsilon_greedy(Q, next_s)\n",
    "            \n",
    "            q_old = Q[cur_s][cur_a]\n",
    "            Q[cur_s][cur_a] = Q[cur_s][cur_a] + ALPHA * (r + gamma * Q[next_s][next_a] - Q[cur_s][cur_a])\n",
    "\n",
    "            cur_s = next_s\n",
    "            cur_a = next_a\n",
    "            \n",
    "            #update delta\n",
    "            biggest_change = max(biggest_change, np.abs(q_old - Q[cur_s][cur_a]))\n",
    "            deltas.append(biggest_change)\n",
    "        \n",
    "    plt.plot(deltas)\n",
    "    plt.show()\n",
    "    \n",
    "    V = {}\n",
    "    for s in g.actions:\n",
    "        policy[s] = max_dict(Q[s])[0]\n",
    "        V[s] = max_dict(Q[s])[1]\n",
    "    \n",
    "    print(\"finale policy\")\n",
    "    print_policy(policy,g)\n",
    "    \n",
    "    # find V\n",
    "    print(\"final values:\")\n",
    "    print_values(V,g)\n",
    "    \n",
    "    \n",
    "    print(\"state_sample_count: \")\n",
    "    state_sample_count_arr = np.zeros((g.rows, g.columns))\n",
    "    for i in range(g.rows):\n",
    "        for j in range(g.columns):\n",
    "            if (i,j) in state_sample_count:\n",
    "                state_sample_count_arr[i,j] = state_sample_count[(i,j)]\n",
    "    df = pd.DataFrame(state_sample_count_arr)\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331bf9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1), (1, 2), (0, 0), (1, 3), (2, 1), (2, 0), (2, 3), (2, 2), (1, 0), (0, 2), (0, 3)}\n",
      "rewards : \n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finale policy\n",
      "---------------------------\n",
      " R | R | R |   |\n",
      "---------------------------\n",
      " U |   | U |   |\n",
      "---------------------------\n",
      " U | L | U | L |\n",
      "final values:\n",
      "---------------------------\n",
      " 0.79| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.71| 0.00| 0.88| 0.00|\n",
      "---------------------------\n",
      " 0.63| 0.55| 0.47| 0.02|\n",
      "state_sample_count: \n",
      "         0        1        2     3\n",
      "0  11185.0  11081.0  10801.0   0.0\n",
      "1  11117.0      0.0    340.0   0.0\n",
      "2  11120.0    338.0     75.0  78.0\n"
     ]
    }
   ],
   "source": [
    "main(-0.05, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514294da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
