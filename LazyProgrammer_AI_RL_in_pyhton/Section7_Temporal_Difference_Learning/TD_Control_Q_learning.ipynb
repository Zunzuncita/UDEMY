{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de8527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment description\n",
    "rewards={(0,3):1,(1,3):-1}\n",
    "\n",
    "actions={\n",
    "    (2,0):['U','R'],\n",
    "    (1,0):['U','D'],\n",
    "    (0,0):['R','D'],\n",
    "    (2,1):['R','L'],\n",
    "    (0,1):['R','L'],\n",
    "    (2,2):['U','R','L'],\n",
    "    (1,2):['U','D','R'],\n",
    "    (0,2):['R','L','D'],\n",
    "    (2,3):['L'],\n",
    "}\n",
    "\n",
    "probs = {\n",
    "    ((2, 0), 'U'): {(1, 0): 1.0},\n",
    "    ((2, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 0), 'R'): {(2, 1): 1.0},\n",
    "    ((1, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((1, 0), 'D'): {(2, 0): 1.0},\n",
    "    ((1, 0), 'L'): {(1, 0): 1.0},\n",
    "    ((1, 0), 'R'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'U'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'D'): {(1, 0): 1.0},\n",
    "    ((0, 0), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 0), 'R'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'U'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'D'): {(0, 1): 1.0},\n",
    "    ((0, 1), 'L'): {(0, 0): 1.0},\n",
    "    ((0, 1), 'R'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'U'): {(0, 2): 1.0},\n",
    "    ((0, 2), 'D'): {(1, 2): 1.0},\n",
    "    ((0, 2), 'L'): {(0, 1): 1.0},\n",
    "    ((0, 2), 'R'): {(0, 3): 1.0},\n",
    "    ((2, 1), 'U'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'D'): {(2, 1): 1.0},\n",
    "    ((2, 1), 'L'): {(2, 0): 1.0},\n",
    "    ((2, 1), 'R'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'U'): {(1, 2): 1.0},\n",
    "    ((2, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((2, 2), 'L'): {(2, 1): 1.0},\n",
    "    ((2, 2), 'R'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'U'): {(1, 3): 1.0},\n",
    "    ((2, 3), 'D'): {(2, 3): 1.0},\n",
    "    ((2, 3), 'L'): {(2, 2): 1.0},\n",
    "    ((2, 3), 'R'): {(2, 3): 1.0},\n",
    "    ((1, 2), 'U'): {(0, 2): 0.5, (1, 3): 0.5},\n",
    "    ((1, 2), 'D'): {(2, 2): 1.0},\n",
    "    ((1, 2), 'L'): {(1, 2): 1.0},\n",
    "    ((1, 2), 'R'): {(1, 3): 1.0},\n",
    "  }\n",
    "\n",
    "policy = {\n",
    "    (2, 0): 'U',\n",
    "    (1, 0): 'U',\n",
    "    (0, 0): 'R',\n",
    "    (0, 1): 'R',\n",
    "    (0, 2): 'R',\n",
    "    (1, 2): 'R',\n",
    "    (2, 1): 'R',\n",
    "    (2, 2): 'R',\n",
    "    (2, 3): 'U'\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47134f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class WindyGridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions, probs):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.probs = probs\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        #print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "    \n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        cur_state = (self.i, self.j)\n",
    "        a = action\n",
    "        next_action_prob = self.probs[(cur_state,a)]\n",
    "        next_actions = list(next_action_prob.keys())\n",
    "        next_probs = list(next_action_prob.values())\n",
    "        next_state_idx = np.random.choice(len(next_actions), p=next_probs)\n",
    "        self.i = next_actions[next_state_idx][0]\n",
    "        self.j = next_actions[next_state_idx][1]\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d089207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gridworld  class\n",
    "class GridWorld():\n",
    "    \n",
    "    def __init__(self, rows, columns, start_position):\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        #self.all_states = [(i,j) for i in range(rows) for j in range(columns)]\n",
    "        self.i = start_position[0]\n",
    "        self.j = start_position[1]\n",
    "        \n",
    "    def set_rewards_actions(self, rewards, actions):\n",
    "        self.rewards = rewards\n",
    "        self.actions = actions\n",
    "        self.all_states = set(self.actions.keys()) | set(self.rewards.keys())\n",
    "        print (self.all_states)\n",
    "    \n",
    "    def set_state(self, s):\n",
    "        self.i = s[0]\n",
    "        self.j = s[1]\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "\n",
    "    def reset(self):\n",
    "        self.i = 2\n",
    "        self.j = 0\n",
    "        return self.current_state()\n",
    "    \n",
    "    def get_next_state(self, s, a):\n",
    "        i, j = s[0], s[1]\n",
    "        #print(f\"s : ({i},{j})\")\n",
    "        #print(a)\n",
    "        #print(self.actions[(i,j)])\n",
    "        if a in self.actions[(i,j)]:\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            elif a == 'R':\n",
    "                j += 1\n",
    "            elif a == 'L':\n",
    "                j -= 1\n",
    "            else:\n",
    "                i += 1\n",
    "        #print(f\"s2 : ({i},{j})\")\n",
    "        return i,j\n",
    "    \n",
    "    def undo_move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i += 1\n",
    "            elif action == 'R':\n",
    "                self.j -= 1\n",
    "            elif action == 'L':\n",
    "                self.j += 1\n",
    "            else:\n",
    "                self.i -= 1\n",
    "        # should never happen\n",
    "        assert (self.current_state() in self.all_states)\n",
    " \n",
    "    def move(self, action):\n",
    "        if action in self.actions[(self.i,self.j)]:\n",
    "            if action == 'U':\n",
    "                self.i -= 1\n",
    "            elif action == 'R':\n",
    "                self.j += 1\n",
    "            elif action == 'L':\n",
    "                self.j -= 1\n",
    "            else:\n",
    "                self.i += 1\n",
    "        return self.rewards.get((self.i,self.j),0)\n",
    "\n",
    "    def is_terminal (self, s):\n",
    "        return s not in self.actions\n",
    "    \n",
    "    def game_over(self):\n",
    "        return (self.i,self.j) in self.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f02f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values(V,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            v = V.get((i,j),0)\n",
    "            if v >= 0:\n",
    "                print(\" %.2f|\" % v, end=\"\")\n",
    "            else:\n",
    "                print(\"%.2f|\" % v, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "def print_policy(P,g):\n",
    "    for i in range(g.rows):\n",
    "        print(\"---------------------------\")\n",
    "        for j in range(g.columns):\n",
    "            a = P.get((i,j),' ')\n",
    "            print(\" %s |\" % a, end=\"\")\n",
    "        print (\"\")\n",
    "\n",
    "ACTION_SPACE = ('U', 'D', 'L', 'R')\n",
    "\n",
    "def init_windy_grid_world_penalized(step_cost, start):\n",
    "    grid = WindyGridWorld(3,4,start)\n",
    "    rewards = {\n",
    "        (2,0):step_cost,\n",
    "        (1,0):step_cost,\n",
    "        (0,0):step_cost,\n",
    "        (2,1):step_cost,\n",
    "        (0,1):step_cost,\n",
    "        (2,2):step_cost,\n",
    "        (1,2):step_cost,\n",
    "        (0,2):step_cost,\n",
    "        (2,3):step_cost,\n",
    "        (0,3):1,\n",
    "        (1,3):-1\n",
    "    }\n",
    "    grid.set_rewards_actions(rewards, actions, probs)\n",
    "    return grid\n",
    "\n",
    "def max_dict(d):\n",
    "    '''\n",
    "    return the argmax and max value from a dictionnary\n",
    "    '''\n",
    "    max_val = max(d.values())\n",
    "    max_keys = [key for key, val in d.items() if val == max_val]\n",
    "    return np.random.choice(max_keys), max_val\n",
    "\n",
    "def epsilon_greedy(Q, state, eps=0.1):\n",
    "    '''\n",
    "    return an actions based on the epsilon greedy concept : exploration vs exploitation\n",
    "    random action if < epx else best action\n",
    "    '''\n",
    "    p = np.random.random()\n",
    "    if p < eps:\n",
    "        a = np.random.choice(ACTION_SPACE)\n",
    "    else:\n",
    "        a = max_dict(Q[state])[0]\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6764aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-3\n",
    "\n",
    "def main(step_cost, tot_iteration):\n",
    "    \n",
    "    gamma = 0.9    \n",
    "    ALPHA = 0.1\n",
    "        \n",
    "    # initialize G and returns\n",
    "    #g = init_grid_world_penalized(step_cost, (2,0))\n",
    "    g = GridWorld(3,4,(2,0))\n",
    "    g.set_rewards_actions(rewards=rewards, actions=actions)\n",
    "    \n",
    "    print(f\"rewards : \")\n",
    "    print_values(g.rewards,g)\n",
    "    \n",
    "   \n",
    "    # initialize Q(s,a) and returns\n",
    "    Q = {}\n",
    "    state_sample_count = {}\n",
    "    states = g.all_states\n",
    "    for s in states:\n",
    "        Q[s]={}\n",
    "        for a in ACTION_SPACE:\n",
    "            Q[s][a]=0\n",
    "        state_sample_count[s]=0 \n",
    "      \n",
    "    # repeat until convergence\n",
    "    deltas = []\n",
    "    #loop on tot_iteration\n",
    "    for t in range(tot_iteration):\n",
    "        if t % 1000 == 0:\n",
    "            print(t)\n",
    "      \n",
    "        # play one game based on a random policy\n",
    "        biggest_change = 0\n",
    "        #print_policy(policy,g)\n",
    "        \n",
    "        cur_s = g.reset()\n",
    "                \n",
    "        #compute Q based on rewards and next state/action\n",
    "        while g.game_over():\n",
    "            state_sample_count[cur_s] += 1 \n",
    "            a = epsilon_greedy(Q,cur_s)           \n",
    "            r = g.move(a)\n",
    "            next_s = g.current_state()  \n",
    "                        \n",
    "            q_old = Q[cur_s][a]\n",
    "            Q[cur_s][a] = Q[cur_s][a] + ALPHA * (r + gamma * max_dict(Q[next_s])[1] - Q[cur_s][a])\n",
    "\n",
    "            cur_s = next_s\n",
    "            \n",
    "            #update delta\n",
    "            biggest_change = max(biggest_change, np.abs(q_old - max_dict(Q[cur_s])[1]))\n",
    "            deltas.append(biggest_change)\n",
    "        \n",
    "    plt.plot(deltas)\n",
    "    plt.show()\n",
    "    \n",
    "    V = {}\n",
    "    for s in g.actions:\n",
    "        policy[s] = max_dict(Q[s])[0]\n",
    "        V[s] = max_dict(Q[s])[1]\n",
    "    \n",
    "    print(\"finale policy\")\n",
    "    print_policy(policy,g)\n",
    "    \n",
    "    # find V\n",
    "    print(\"final values:\")\n",
    "    print_values(V,g)\n",
    "    \n",
    "    \n",
    "    print(\"state_sample_count: \")\n",
    "    state_sample_count_arr = np.zeros((g.rows, g.columns))\n",
    "    for i in range(g.rows):\n",
    "        for j in range(g.columns):\n",
    "            if (i,j) in state_sample_count:\n",
    "                state_sample_count_arr[i,j] = state_sample_count[(i,j)]\n",
    "    df = pd.DataFrame(state_sample_count_arr)\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331bf9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1), (1, 2), (0, 0), (1, 3), (2, 1), (2, 0), (2, 3), (2, 2), (1, 0), (0, 2), (0, 3)}\n",
      "rewards : \n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finale policy\n",
      "---------------------------\n",
      " R | R | R |   |\n",
      "---------------------------\n",
      " U |   | U |   |\n",
      "---------------------------\n",
      " U | L | U | L |\n",
      "final values:\n",
      "---------------------------\n",
      " 0.81| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.90| 0.00|\n",
      "---------------------------\n",
      " 0.66| 0.59| 0.65| 0.00|\n",
      "state_sample_count: \n",
      "         0        1        2     3\n",
      "0  11110.0  11057.0  10841.0   0.0\n",
      "1  11067.0      0.0    323.0   0.0\n",
      "2  11097.0    336.0     60.0  48.0\n"
     ]
    }
   ],
   "source": [
    "main(-0.05, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514294da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
